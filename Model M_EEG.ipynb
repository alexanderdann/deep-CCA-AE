{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b54e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.utils import gen_batches\n",
    "import shutil\n",
    "from correlation_analysis import CCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import build_deepCCA_model, compute_loss, CCA, compute_regularization, compute_termination_score\n",
    "\n",
    "from tensorboard_utillities import write_scalar_summary, write_image_summary, write_PCC_summary, write_gradients_summary_mean, write_poly\n",
    "from tensorboard_utillities import create_grid_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01bbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = scipy.io.loadmat('eeg_data.mat')['data'][:, :, 0:172]\n",
    "meg = scipy.io.loadmat('meg_data.mat')['data']\n",
    "labels = [int(i) for i in scipy.io.loadmat('labels.mat')['L']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445fbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels):\n",
    "    channels, samples, trials = data.shape\n",
    "    y = np.array([label*np.ones(161) for label in labels]).flatten()\n",
    "    X = np.reshape(data, (channels, samples*trials)).T\n",
    "\n",
    "    X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.10)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_tmp, y_tmp, test_size=0.50)\n",
    "\n",
    "    return {'train': {'data': X_train.T, 'labels': y_train},\n",
    "            'validation': {'data': X_val.T, 'labels': y_val},\n",
    "            'test': {'data': X_test.T, 'labels': y_test}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007705ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24922,), (1385,), (1385,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data = split_data(eeg, labels)\n",
    "meg_data = split_data(meg, labels)\n",
    "eeg_data['train']['labels'].shape, meg_data['test']['labels'].shape, meg_data['validation']['labels'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4be76314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data, batch_size):\n",
    "    channels, samples = data.shape\n",
    "    num_batches = samples // batch_size\n",
    "\n",
    "    tmp = np.zeros(shape=(num_batches, batch_size, channels), dtype=np.float32)\n",
    "    for batch_idx, indeces in enumerate(gen_batches(samples, batch_size)):\n",
    "        tmp[batch_idx] = data[:, indeces].T\n",
    "\n",
    "    return tf.convert_to_tensor(tmp, dtype=tf.float32), num_batches\n",
    "\n",
    "\n",
    "def train(train_data, train_labels, validation_data, validation_labels,\n",
    "          max_epochs, batch_size, log_path, model_path, shared_dim=5, iter_idx=1):\n",
    "\n",
    "    y_1, num_batches_1 = batch_data(train_data[0], batch_size)\n",
    "    y_2, num_batches_2 = batch_data(train_data[1], batch_size)\n",
    "    assert num_batches_1 == num_batches_2\n",
    "\n",
    "    writer = create_grid_writer(root_dir=log_path, params=['deepCCA', f'v{iter_idx}', f'Shared dim {shared_dim}'])\n",
    "    try:\n",
    "        mpath = f'{model_path}/v{iter_idx}-SharedDim-{shared_dim}-BatchSize-{batch_size}'\n",
    "        model = tf.keras.models.load_model(mpath)\n",
    "        print('Loading existing model.\\n')\n",
    "    except:\n",
    "        model = build_deepCCA_model([256, 256, 256], shared_dim)\n",
    "\n",
    "    termination_condition = False\n",
    "    termination_score_history = list()\n",
    "    \n",
    "    for epoch in tqdm(range(max_epochs), desc='Epochs'):\n",
    "        if termination_condition:\n",
    "            break\n",
    "        \n",
    "        losses, cca_losses, reg_losses = list(), list(), list()\n",
    "        intermediate_outputs = list()\n",
    "        for batch_idx in range(num_batches_1):\n",
    "            batch_y1, batch_y2 = y_1[batch_idx], y_2[batch_idx]\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch([batch_y1, batch_y2])\n",
    "                fy_1, fy_2 = model([batch_y1, batch_y2])\n",
    "                cca_loss = compute_loss(fy_1, fy_2)\n",
    "                reg_loss = compute_regularization(model, lambda_reg=1e-6)\n",
    "                if epoch >= 5:\n",
    "                    loss = cca_loss + reg_loss\n",
    "                else:\n",
    "                    loss = cca_loss\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                intermediate_outputs.append((fy_1, fy_2))\n",
    "                # Keeping track of losses\n",
    "                cca_losses.append(cca_loss); reg_losses.append(reg_loss); losses.append(loss)\n",
    "                \n",
    "        if epoch % 25 == 0:\n",
    "            tmp = list()\n",
    "            for batch_idx in range(num_batches_2):\n",
    "                batched_fy_1, batched_fy_2 = intermediate_outputs[batch_idx]\n",
    "                B1, B2, epsilon, omega, ccor = CCA(batched_fy_1, batched_fy_2)\n",
    "                tmp.append(ccor)\n",
    "            avg_ccor = tf.math.reduce_mean(tmp, axis=0)\n",
    "            static_part = [(tf.math.reduce_mean(losses), 'Loss/Total'),\n",
    "                           (tf.math.reduce_mean(cca_losses), 'Loss/CCA'),\n",
    "                           (tf.math.reduce_mean(reg_losses), 'Loss/Regularization'),\n",
    "                           (tf.math.reduce_mean(termination_score_history[-5:]), 'Score/Value')]\n",
    "            dynamic_part = [(cval, f'Canonical correlation/{idx})') for idx, cval in enumerate(avg_ccor)]\n",
    "            write_scalar_summary(\n",
    "                writer=writer,\n",
    "                epoch=epoch,\n",
    "                list_of_tuples=static_part + dynamic_part\n",
    "            )\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            val_fy_1, val_fy_2 = model([validation_data[0].T, validation_data[1].T])\n",
    "            tscore_view1 = compute_termination_score(fy_1, train_labels[0], val_fy_1, validation_labels[0])\n",
    "            tscore_view2 = compute_termination_score(fy_2, train_labels[1], val_fy_2, validation_labels[1])\n",
    "            tscore = tf.reduce_mean(np.array([tscore_view1, tscore_view2]))\n",
    "            termination_score_history.append(tscore)\n",
    "            if (tscore.numpy() < np.mean(termination_score_history[-6:-1])) and (epoch >= 300):\n",
    "                termination_condition = True\n",
    "                \n",
    "        if epoch % 250 == 0:\n",
    "            try:\n",
    "                os.makedirs(model_path)\n",
    "            except FileExistsError:\n",
    "                print('MODELS PATH exists, saving data.')\n",
    "            finally:\n",
    "                model.save(f'{model_path}/v{iter_idx}-SharedDim-{shared_dim}-BatchSize-{batch_size}/model.tf', overwrite=True)\n",
    "                with open(f'{model_path}/v{iter_idx}-SharedDim-{shared_dim}-BatchSize-{batch_size}/modellog.txt', 'a+') as f:\n",
    "                    f.write(f'Saving model at epoch {epoch}\\n')\n",
    "    \n",
    "                        \n",
    "def test(model, train_data, train_labels, validation_data, validation_labels, test_data, test_labels):\n",
    "    p_fy_1, p_fy_2 = model([train_data[0].T, train_data[1].T])\n",
    "    v_fy_1, v_fy_2 = model([validation_data[0].T, validation_data[1].T])\n",
    "    \n",
    "    s_fy_1, s_fy_2 = tf.concat([p_fy_1, v_fy_1], axis=0), tf.concat([p_fy_2, v_fy_2], axis=0)\n",
    "    labels_1 = tf.concat([train_labels[0], validation_labels[0]], axis=0)\n",
    "    labels_2 = tf.concat([train_labels[1], validation_labels[1]], axis=0)\n",
    "    \n",
    "    fy_1, fy_2 = model([test_data[0].T, test_data[1].T])\n",
    "    score_view1 = compute_termination_score(s_fy_1, labels_1, fy_1, test_labels[0])\n",
    "    score_view2 = compute_termination_score(s_fy_2, labels_2, fy_2, test_labels[1])\n",
    "    \n",
    "    return [score_view1, score_view2]\n",
    "\n",
    "def test_raw(train_data, train_labels, validation_data, validation_labels, test_data, test_labels):\n",
    "    view_1 = tf.concat([train_data[0].T, validation_data[0].T], axis=0)\n",
    "    view_2 = tf.concat([train_data[1].T, validation_data[1].T], axis=0)\n",
    "    \n",
    "    labels_1 = tf.concat([train_labels[0], validation_labels[0]], axis=0)\n",
    "    labels_2 = tf.concat([train_labels[1], validation_labels[1]], axis=0)\n",
    "    \n",
    "    score_view1 = compute_termination_score(view_1, labels_1, tf.convert_to_tensor(test_data[0].T), test_labels[0])\n",
    "    score_view2 = compute_termination_score(view_2, labels_2, tf.convert_to_tensor(test_data[1].T), test_labels[1])\n",
    "    \n",
    "    return [score_view1, score_view2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9521b49c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepCCA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer_1 (InputLayer)      [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_Layer_2 (InputLayer)      [(None, 151)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H1 (Dense)         (None, 256)          33536       Input_Layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H1 (Dense)         (None, 256)          38912       Input_Layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H2 (Dense)         (None, 256)          65792       View_1_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H2 (Dense)         (None, 256)          65792       View_2_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H3 (Dense)         (None, 256)          65792       View_1_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H3 (Dense)         (None, 256)          65792       View_2_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_1 (Dense)          (None, 5)            1285        View_1_Layer_H3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_2 (Dense)          (None, 5)            1285        View_2_Layer_H3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 338,186\n",
      "Trainable params: 338,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                                                                 | 0/2000 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v0-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v0-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  12%|██████████▉                                                                            | 250/2000 [01:49<12:32,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v0-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v0-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  23%|███████████████████▌                                                                   | 451/2000 [03:16<11:14,  2.30it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepCCA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer_1 (InputLayer)      [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_Layer_2 (InputLayer)      [(None, 151)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H1 (Dense)         (None, 256)          33536       Input_Layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H1 (Dense)         (None, 256)          38912       Input_Layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H2 (Dense)         (None, 256)          65792       View_1_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H2 (Dense)         (None, 256)          65792       View_2_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H3 (Dense)         (None, 256)          65792       View_1_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H3 (Dense)         (None, 256)          65792       View_2_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_1 (Dense)          (None, 5)            1285        View_1_Layer_H3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_2 (Dense)          (None, 5)            1285        View_2_Layer_H3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 338,186\n",
      "Trainable params: 338,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                                                                 | 0/2000 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v1-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v1-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  12%|██████████▉                                                                            | 250/2000 [01:46<12:13,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v1-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v1-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  15%|█████████████                                                                          | 301/2000 [02:09<12:13,  2.32it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepCCA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer_1 (InputLayer)      [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_Layer_2 (InputLayer)      [(None, 151)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H1 (Dense)         (None, 256)          33536       Input_Layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H1 (Dense)         (None, 256)          38912       Input_Layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H2 (Dense)         (None, 256)          65792       View_1_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H2 (Dense)         (None, 256)          65792       View_2_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H3 (Dense)         (None, 256)          65792       View_1_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H3 (Dense)         (None, 256)          65792       View_2_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_1 (Dense)          (None, 5)            1285        View_1_Layer_H3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_2 (Dense)          (None, 5)            1285        View_2_Layer_H3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 338,186\n",
      "Trainable params: 338,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                                                                 | 0/2000 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v2-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v2-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  12%|██████████▉                                                                            | 250/2000 [01:47<12:22,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v2-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v2-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  15%|█████████████                                                                          | 301/2000 [02:10<12:18,  2.30it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepCCA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer_1 (InputLayer)      [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_Layer_2 (InputLayer)      [(None, 151)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H1 (Dense)         (None, 256)          33536       Input_Layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H1 (Dense)         (None, 256)          38912       Input_Layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H2 (Dense)         (None, 256)          65792       View_1_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H2 (Dense)         (None, 256)          65792       View_2_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H3 (Dense)         (None, 256)          65792       View_1_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H3 (Dense)         (None, 256)          65792       View_2_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_1 (Dense)          (None, 5)            1285        View_1_Layer_H3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_2 (Dense)          (None, 5)            1285        View_2_Layer_H3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 338,186\n",
      "Trainable params: 338,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                                                                 | 0/2000 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  12%|██████████▉                                                                            | 250/2000 [01:44<12:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  25%|█████████████████████▊                                                                 | 500/2000 [03:32<10:32,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  38%|████████████████████████████████▋                                                      | 750/2000 [05:19<08:48,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v3-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  38%|████████████████████████████████▋                                                      | 751/2000 [05:21<08:54,  2.34it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepCCA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer_1 (InputLayer)      [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_Layer_2 (InputLayer)      [(None, 151)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H1 (Dense)         (None, 256)          33536       Input_Layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H1 (Dense)         (None, 256)          38912       Input_Layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H2 (Dense)         (None, 256)          65792       View_1_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H2 (Dense)         (None, 256)          65792       View_2_Layer_H1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_1_Layer_H3 (Dense)         (None, 256)          65792       View_1_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "View_2_Layer_H3 (Dense)         (None, 256)          65792       View_2_Layer_H2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_1 (Dense)          (None, 5)            1285        View_1_Layer_H3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer_2 (Dense)          (None, 5)            1285        View_2_Layer_H3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 338,186\n",
      "Trainable params: 338,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                                                                 | 0/2000 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v4-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v4-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  12%|██████████▉                                                                            | 250/2000 [01:47<12:17,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS PATH exists, saving data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_Layer_1, Input_Layer_2 with unsupported characters which will be renamed to input_layer_1, input_layer_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v4-SharedDim-5-BatchSize-24922/model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/alexander/Documents/Uni/Work/Repositories/deep-CCA-tf/MODELS/MEEG-EEG/v4-SharedDim-5-BatchSize-24922/model.tf/assets\n",
      "Epochs:  15%|█████████████                                                                          | 301/2000 [02:10<12:14,  2.31it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = list()\n",
    "raw_results = list()\n",
    "\n",
    "for iter_idx in range(5):\n",
    "    desc = 'MEEG-EEG'\n",
    "    LOGPATH = f'{os.getcwd()}/LOG/{desc}'\n",
    "    MODELSPATH = f'{os.getcwd()}/MODELS/{desc}'\n",
    "    \n",
    "    eeg_data = split_data(eeg, labels)\n",
    "    meg_data = split_data(meg, labels)\n",
    "\n",
    "    train(train_data=[eeg_data['train']['data'], meg_data['train']['data']], \n",
    "          train_labels=[eeg_data['train']['labels'], meg_data['train']['labels']],\n",
    "          validation_data=[eeg_data['validation']['data'], meg_data['validation']['data']], \n",
    "          validation_labels=[eeg_data['validation']['labels'], meg_data['validation']['labels']],\n",
    "          max_epochs=2000, batch_size=24922, log_path=LOGPATH, model_path=MODELSPATH, iter_idx=iter_idx)\n",
    "    \n",
    "    model = model = tf.keras.models.load_model(f'{MODELSPATH}/SharedDim-5-BatchSize-24922/model.tf')\n",
    "    tmp = test(model,\n",
    "               train_data=[eeg_data['train']['data'], meg_data['train']['data']],\n",
    "               train_labels=[eeg_data['train']['labels'], meg_data['train']['labels']],\n",
    "               validation_data=[eeg_data['validation']['data'], meg_data['validation']['data']], \n",
    "               validation_labels=[eeg_data['validation']['labels'], meg_data['validation']['labels']],\n",
    "               test_data=[eeg_data['test']['data'], meg_data['test']['data']],\n",
    "               test_labels=[eeg_data['test']['labels'], meg_data['test']['labels']])\n",
    "    results.append(tmp)\n",
    "    \n",
    "    tmp = test_raw(train_data=[eeg_data['train']['data'], meg_data['train']['data']],\n",
    "                   train_labels=[eeg_data['train']['labels'], meg_data['train']['labels']],\n",
    "                   validation_data=[eeg_data['validation']['data'], meg_data['validation']['data']], \n",
    "                   validation_labels=[eeg_data['validation']['labels'], meg_data['validation']['labels']],\n",
    "                   test_data=[eeg_data['test']['data'], meg_data['test']['data']],\n",
    "                   test_labels=[eeg_data['test']['labels'], meg_data['test']['labels']])\n",
    "    raw_results.append(tmp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af770b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.49285199, 0.49718412]), array([0.48418773, 0.49891697]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.mean(raw_results, axis=0), 1-np.mean(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b7619f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.527797833935018, 0.5010830324909747],\n",
       "  [0.5371841155234657, 0.4815884476534296],\n",
       "  [0.48592057761732854, 0.5054151624548736],\n",
       "  [0.503971119133574, 0.5140794223826715],\n",
       "  [0.524187725631769, 0.5032490974729242]],\n",
       " [[0.4844765342960289, 0.496028880866426],\n",
       "  [0.5314079422382672, 0.5010830324909747],\n",
       "  [0.5068592057761733, 0.49097472924187724],\n",
       "  [0.503971119133574, 0.5104693140794224],\n",
       "  [0.5090252707581228, 0.5155234657039711]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, raw_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071727b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
